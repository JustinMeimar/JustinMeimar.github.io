---
title: HackGPT Edmonton
layout: page
date: 2023-07-27
---

A couple of weeks ago, my friend Seif gave me a call. Just like that HackGPT --  Edmonton's first large language model Hackathon was on.

The event was sponsored and organized by a company called [Place](https://place.com). Since they are a Real Estate company, bonus points were given to teams whose project related to the industry. 

Aziz had the idea to develop an interface that allowed users to chat with homes in their area, and prompt semantic queries like *Show me some apartments with a view of the North Saskatchewan river.* 

Kevin and I got to work on the nuts and bolts of the applications, while Seif and Aziz tinkered with the crucial task of embedding the listing data. Our approach was to embed the textual description of each listing, while the remaining JSON fields were repurposed as metadata. This way, we could retrieve exact queries for quantitative attributes like number of bedrooms and bathrooms or min and max price. And for qualitative attributes, once the metadata had narrowed down the listing choices, we could select the top_n vectors with the maximum [Cosine Similarity](https://), then render each original listing on the frontend.  

We employed techniques like prompt-chaining to generate richer, standardized query templates. We also used a long-term memory approach, ensuring that each user interaction carried over to subsequent ones.

As is typical in Hackathons, we had a number of unpolished features. I had to give up on drawing the map markers in the last five minutes, even though the latitude and longitude data was right at my finger tips! Some rough edges notwithstanding, we had a solid presentation and put strong emphasis on how a future data engine could be greatly improved.  

One of our ideas was to run image-to-text models to extract descriptions from the 
multiple listing photos. Then we could append these extractions to the existing listing description and embed the entire batch. 

Another idea was to allow users to upload several images, and then have our system compare these in the embedded photo space against the gallery images. Essentially using images as the IR rather than natural language. Imagine someone who has Pinterest board with some aesthetic theme. They could upload the board and search for that one house in America that best matches the aesthetic. 

AI-embedded applications can be taken in many directions. While our product was far from perfect, we manage to walk away with first place! 

Here is our [HackGPT Repo](https://github.com/JustinMeimar/hack-gpt)

Thanks for reading,

\- Justin